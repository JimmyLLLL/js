事实上乱序一个数组不仅仅是前端课题，那么这个问题在前端的背景下，有哪些特点呢？可能有读者首先想到使用数组的 sort API，再结合 Math.random 实现：

['A','B','C','D'...].sort(function() {
    return .5 - Math.random();
})
这样的思路非常自然，但也许你不知道：这不是真正意义上的完全乱序

比如，A 元素大概率出现在数组的头部，J 元素大概率出现在数组的尾部，所有元素大概率停留在自己初始位置。

其实不管用什么排序方法，大多数排序算法的时间复杂度介于 O(n) 到 O(n2) 之间，
元素之间的比较次数通常情况下要远小于 n(n-1)/2，也就意味着有一些元素之间根本就没机会相比较（也就没有了随机交换的可能），
这些 sort 随机排序的算法自然也不能真正随机。

通俗地说，其实我们使用 array.sort 进行乱序，理想的方案或者说纯乱序的方案是：数组中每两个元素都要进行比较，这个比较有 50% 的交换位置概率。如此一来，总共比较次数一定为 n(n-1)。
而在 sort 排序算法中，大多数情况都不会满足这样的条件，因此当然不是完全随机的结果了。

没有循环语句，时间复杂度记作 O(1)，我们称为常数阶；
只有一重循环，那么算法的基本操作的执行频度与问题规模 n 呈线性增大关系，记作 O（n），也叫线性阶。

我们再看一个对数阶的概念：
const aFun = n => {
  let i = 1;
  while (i <= n)  {
     i = i * 2
  }
  return i
}

const cal = n => { 
   let sum = 0
   for (let i = 1; i <= n; ++i) {
     sum = sum + aFun(n)
   }
   return sum
 }
 

 2^0 * 2^1 * 2^2 * 2^k * 2^x(次数最高取它) = n
 2^x = n
 x = logn

 但是不知道读者有没有发现：不管是以 2 为底，还是以 K 为底，我们似乎都把所有对数阶的时间复杂度都记为 O(logn)。这又是为什么呢？

 由于时间复杂度描述的是算法执行时间与数据规模的增长变化趋势，因而常量、低阶、系数实际上对这种增长趋势不产生决定性影响，所以在做时间复杂度分析时忽略这些项。

 最好、最坏时间复杂度，平均时间复杂度，均摊时间复杂度

 const find = (array, x) => {
     let pos = -1
     let n = array.length

     for (let i = 0; i < n; ++i) {
            if (array[i] === x) {
                 pos = i 
                 break
            }
      }
      return pos
}
在找到第一个匹配元素后，循环终止，那么时间复杂度就不一定是 O(n) 了，因此就有了最好时间复杂度、最坏时间复杂度的区别。针对上述代码最好时间复杂度就是 O(1)、最坏时间复杂度还是 O(n)。

在上述代码中，平均时间复杂度的计算方式应该是：

(1/(n+1)) * 1 + (1/(n+1)) * 2 + ... + (1/(n+1)) * n + (1/(n+1)) * n
得到结果为：n(n+3)/2(n+1)

O(1)：基本运算 +、-、*、/、%、寻址
O(logn)：二分查找，跟分治（Divide & Conquer）相关的基本上都是 logn
O(n)：线性查找
O(nlogn)：归并排序，快速排序的期望复杂度，基于比较排序的算法下界
O(n²)：冒泡排序，插入排序，朴素最近点对
O(n³)：Floyd 最短路，普通矩阵乘法
O(2ⁿ)：枚举全部子集
O(n!)：枚举全排列